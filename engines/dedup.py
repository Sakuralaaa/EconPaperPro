# -*- coding: utf-8 -*-
"""
é™é‡å¼•æ“æ¨¡å—
å­¦æœ¯çº§æ–‡æœ¬æ”¹å†™ï¼Œé™ä½é‡å¤ç‡
"""

from typing import List, Optional, Dict, Tuple
from dataclasses import dataclass, field
from core.llm import get_llm_client
from core.prompts import PromptTemplates

# é…ç½®å¸¸é‡
MAX_CHANGES_TO_REPORT = 5  # æœ€å¤šæŠ¥å‘Šçš„å˜åŒ–æ¡æ•°


@dataclass
class DedupResult:
    """é™é‡ç»“æœ"""
    original: str
    processed: str
    changes: List[str]
    similarity_before: float
    similarity_after: float
    preserved_terms: List[str] = field(default_factory=list)


class DedupEngine:
    """
    é™é‡å¼•æ“
    
    å¯¹å­¦æœ¯æ–‡æœ¬è¿›è¡Œæ”¹å†™ï¼Œé™ä½ä¸åŸæ–‡çš„ç›¸ä¼¼åº¦
    
    ä½¿ç”¨ç¤ºä¾‹:
        engine = DedupEngine()
        result = engine.process(content, strength=3)
    """
    
    # é»˜è®¤ä¿ç•™çš„å­¦æœ¯æœ¯è¯­
    DEFAULT_PRESERVE_TERMS = [
        # è®¡é‡æ–¹æ³•
        "åŒé‡å·®åˆ†", "DID", "difference-in-differences", "å·®åˆ†",
        "å€¾å‘å¾—åˆ†åŒ¹é…", "PSM", "propensity score matching",
        "å·¥å…·å˜é‡", "IV", "instrumental variable", "2SLS", "ä¸¤é˜¶æ®µæœ€å°äºŒä¹˜",
        "æ–­ç‚¹å›å½’", "RDD", "regression discontinuity", "æ–­ç‚¹è®¾è®¡",
        "å›ºå®šæ•ˆåº”", "fixed effects", "FE", "ä¸ªä½“å›ºå®šæ•ˆåº”", "æ—¶é—´å›ºå®šæ•ˆåº”",
        "éšæœºæ•ˆåº”", "random effects", "RE",
        "é¢æ¿æ•°æ®", "panel data", "å¹³è¡¡é¢æ¿", "éå¹³è¡¡é¢æ¿",
        "å¹¿ä¹‰çŸ©ä¼°è®¡", "GMM", "ç³»ç»ŸGMM", "å·®åˆ†GMM",
        "ä¸­ä»‹æ•ˆåº”", "mediating effect", "ä¸­ä»‹å˜é‡",
        "è°ƒèŠ‚æ•ˆåº”", "moderating effect", "è°ƒèŠ‚å˜é‡",
        "å¼‚è´¨æ€§åˆ†æ", "åˆ†æ ·æœ¬å›å½’",
        "åˆæˆæ§åˆ¶æ³•", "SCM", "synthetic control",
        "äº‹ä»¶ç ”ç©¶æ³•", "event study",
        # ç»Ÿè®¡æœ¯è¯­
        "æ˜¾è‘—æ€§", "significance", "æ˜¾è‘—",
        "ç¨³å¥æ€§", "robustness", "ç¨³å¥æ€§æ£€éªŒ",
        "å†…ç”Ÿæ€§", "endogeneity", "å†…ç”Ÿæ€§é—®é¢˜",
        "å¼‚æ–¹å·®", "heteroskedasticity", "å¼‚æ–¹å·®æ£€éªŒ",
        "è‡ªç›¸å…³", "autocorrelation", "åºåˆ—ç›¸å…³",
        "å¤šé‡å…±çº¿æ€§", "multicollinearity", "VIF",
        "tç»Ÿè®¡é‡", "tå€¼", "t-statistic",
        "Fç»Ÿè®¡é‡", "Få€¼", "F-test",
        "Ræ–¹", "RÂ²", "R-squared", "è°ƒæ•´Ræ–¹",
        "æ ‡å‡†è¯¯", "standard error", "èšç±»æ ‡å‡†è¯¯",
        "ç½®ä¿¡åŒºé—´", "confidence interval",
        "på€¼", "p-value", "æ˜¾è‘—æ€§æ°´å¹³",
        "Bootstrap", "è‡ªåŠ©æ³•",
        # ç»æµå­¦æœ¯è¯­
        "è¾¹é™…æ•ˆåº”", "marginal effect",
        "å¼¹æ€§", "elasticity", "ä»·æ ¼å¼¹æ€§",
        "å¤–éƒ¨æ€§", "externality", "æ­£å¤–éƒ¨æ€§", "è´Ÿå¤–éƒ¨æ€§",
        "ä¿¡æ¯ä¸å¯¹ç§°", "information asymmetry",
        "å§”æ‰˜ä»£ç†", "principal-agent", "ä»£ç†é—®é¢˜",
        "é“å¾·é£é™©", "moral hazard",
        "é€†å‘é€‰æ‹©", "adverse selection",
        "äº¤æ˜“æˆæœ¬", "transaction cost",
        "è§„æ¨¡ç»æµ", "economies of scale",
        "èŒƒå›´ç»æµ", "economies of scope",
        # é‡‘èæœ¯è¯­
        "èµ„äº§å®šä»·", "asset pricing", "CAPM",
        "å¸‚åœºæœ‰æ•ˆæ€§", "market efficiency",
        "ä¿¡æ¯æ•ˆç‡", "information efficiency",
        "èèµ„çº¦æŸ", "financing constraints",
        "ä»£ç†æˆæœ¬", "agency cost",
    ]
    
    def __init__(self):
        """åˆå§‹åŒ–é™é‡å¼•æ“"""
        self._llm = None
    
    @property
    def llm(self):
        """å»¶è¿ŸåŠ è½½LLMå®¢æˆ·ç«¯"""
        if self._llm is None:
            self._llm = get_llm_client()
        return self._llm
    
    def process(
        self,
        content: str,
        strength: int = 3,
        preserve_terms: Optional[List[str]] = None
    ) -> DedupResult:
        """
        æ‰§è¡Œé™é‡å¤„ç†
        
        Args:
            content: åŸå§‹æ–‡æœ¬
            strength: é™é‡å¼ºåº¦ (1-5)
            preserve_terms: éœ€è¦ä¿ç•™çš„ä¸“ä¸šæœ¯è¯­
            
        Returns:
            DedupResult: é™é‡ç»“æœ
        """
        strength = max(1, min(5, strength))
        
        # åˆå¹¶ä¿ç•™æœ¯è¯­
        all_terms = self.DEFAULT_PRESERVE_TERMS.copy()
        if preserve_terms:
            all_terms.extend(preserve_terms)
        
        # åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬
        if len(content) > 2000:
            return self._process_long_text(content, strength, all_terms)
        
        return self._process_single(content, strength, all_terms)
    
    def _process_single(
        self,
        content: str,
        strength: int,
        preserve_terms: List[str]
    ) -> DedupResult:
        """
        å¤„ç†å•æ®µæ–‡æœ¬
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            strength: é™é‡å¼ºåº¦
            preserve_terms: ä¿ç•™æœ¯è¯­
            
        Returns:
            DedupResult: é™é‡ç»“æœ
        """
        # è¯†åˆ«æ–‡æœ¬ä¸­å‡ºç°çš„ä¿ç•™æœ¯è¯­
        found_terms = [t for t in preserve_terms if t in content]
        
        prompt = PromptTemplates.DEDUP_ACADEMIC.format(
            content=content,
            strength=strength,
            preserve_terms=", ".join(found_terms) if found_terms else "æ— "
        )
        
        try:
            processed = self.llm.invoke(
                prompt,
                system_prompt="ä½ æ˜¯å­¦æœ¯å†™ä½œä¸“å®¶ï¼Œæ“…é•¿åœ¨ä¿æŒå­¦æœ¯è§„èŒƒçš„å‰æä¸‹æ”¹å†™æ–‡æœ¬ã€‚"
            )
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity_before = 1.0
            similarity_after = self._calculate_similarity(content, processed)
            
            # è¯†åˆ«å˜åŒ–
            changes = self._identify_changes(content, processed)
            
            return DedupResult(
                original=content,
                processed=processed,
                changes=changes,
                similarity_before=similarity_before,
                similarity_after=similarity_after,
                preserved_terms=found_terms
            )
            
        except Exception as e:
            return DedupResult(
                original=content,
                processed=content,
                changes=[f"å¤„ç†å¤±è´¥: {str(e)}"],
                similarity_before=1.0,
                similarity_after=1.0,
                preserved_terms=found_terms
            )
    
    def _process_long_text(
        self,
        content: str,
        strength: int,
        preserve_terms: List[str]
    ) -> DedupResult:
        """
        å¤„ç†é•¿æ–‡æœ¬ï¼ˆåˆ†æ®µå¤„ç†ï¼‰
        
        Args:
            content: é•¿æ–‡æœ¬
            strength: é™é‡å¼ºåº¦
            preserve_terms: ä¿ç•™æœ¯è¯­
            
        Returns:
            DedupResult: é™é‡ç»“æœ
        """
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split("\n\n")
        processed_paragraphs = []
        all_changes = []
        
        for para in paragraphs:
            if len(para.strip()) < 50:
                # çŸ­æ®µè½ç›´æ¥ä¿ç•™
                processed_paragraphs.append(para)
            else:
                result = self._process_single(para, strength, preserve_terms)
                processed_paragraphs.append(result.processed)
                all_changes.extend(result.changes)
        
        processed = "\n\n".join(processed_paragraphs)
        
        # è®¡ç®—æ•´ä½“ç›¸ä¼¼åº¦
        similarity_after = self._calculate_similarity(content, processed)
        
        # è¯†åˆ«æ–‡æœ¬ä¸­å‡ºç°çš„ä¿ç•™æœ¯è¯­
        found_terms = [t for t in preserve_terms if t in content]
        
        return DedupResult(
            original=content,
            processed=processed,
            changes=list(set(all_changes))[:10],
            similarity_before=1.0,
            similarity_after=similarity_after,
            preserved_terms=found_terms
        )
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        
        Args:
            text1: æ–‡æœ¬1
            text2: æ–‡æœ¬2
            
        Returns:
            float: ç›¸ä¼¼åº¦ (0-1)
        """
        from difflib import SequenceMatcher
        
        # ä½¿ç”¨ SequenceMatcher è®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, text1, text2).ratio()
    
    def _identify_changes(self, original: str, processed: str) -> List[str]:
        """
        è¯†åˆ«ä¸»è¦å˜åŒ–
        
        Args:
            original: åŸå§‹æ–‡æœ¬
            processed: å¤„ç†åæ–‡æœ¬
            
        Returns:
            List[str]: å˜åŒ–æè¿°åˆ—è¡¨
        """
        changes = []
        
        # å­—æ•°å˜åŒ–
        orig_len = len(original)
        proc_len = len(processed)
        len_ratio = proc_len / orig_len if orig_len > 0 else 1
        
        if len_ratio > 1.2:
            changes.append(f"é€‚å½“æ‰©å±•äº†å†…å®¹è¡¨è¿°ï¼ˆå¢åŠ çº¦{int((len_ratio-1)*100)}%ï¼‰")
        elif len_ratio > 1.05:
            changes.append("ç•¥å¾®æ‰©å±•äº†éƒ¨åˆ†è¡¨è¿°")
        elif len_ratio < 0.8:
            changes.append(f"ç²¾ç®€äº†å†—ä½™è¡¨è¾¾ï¼ˆå‡å°‘çº¦{int((1-len_ratio)*100)}%ï¼‰")
        elif len_ratio < 0.95:
            changes.append("ç•¥å¾®ç²¾ç®€äº†éƒ¨åˆ†è¡¨è¿°")
        
        # å¥å­æ•°é‡å˜åŒ–
        orig_sentences = original.count("ã€‚") + original.count(".")
        proc_sentences = processed.count("ã€‚") + processed.count(".")
        
        if proc_sentences > orig_sentences * 1.3:
            changes.append("æ‹†åˆ†äº†é•¿å¥ï¼Œå¢åŠ äº†å¥å­æ•°é‡")
        elif proc_sentences < orig_sentences * 0.7:
            changes.append("åˆå¹¶äº†ç›¸å…³å¥å­ï¼Œå¢å¼ºè¿è´¯æ€§")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æ„è°ƒæ•´
        sequence_markers = ["é¦–å…ˆ", "å…¶æ¬¡", "å†æ¬¡", "æœ€å", "ç¬¬ä¸€", "ç¬¬äºŒ"]
        orig_seq = sum(1 for m in sequence_markers if m in original)
        proc_seq = sum(1 for m in sequence_markers if m in processed)
        if proc_seq < orig_seq:
            changes.append("è°ƒæ•´äº†è®ºè¿°ç»“æ„ï¼Œå‡å°‘åºåˆ—è¯ä½¿ç”¨")
        
        # æ£€æŸ¥åŒä¹‰è¯æ›¿æ¢
        # ç®€å•æ£€æµ‹ï¼šå¦‚æœç›¸ä¼¼åº¦ä¸­ç­‰ä½†å†…å®¹é•¿åº¦ç›¸è¿‘ï¼Œè¯´æ˜è¿›è¡Œäº†åŒä¹‰è¯æ›¿æ¢
        similarity = self._calculate_similarity(original, processed)
        if 0.4 < similarity < 0.8 and 0.9 < len_ratio < 1.1:
            changes.append("è¿›è¡Œäº†åŒä¹‰è¯æ›¿æ¢å’Œè¡¨è¾¾é‡æ„")
        
        # æ£€æŸ¥æ®µè½ç»“æ„å˜åŒ–
        orig_paras = original.count("\n\n")
        proc_paras = processed.count("\n\n")
        if proc_paras > orig_paras + 1:
            changes.append("å¢åŠ äº†æ®µè½åˆ’åˆ†")
        elif proc_paras < orig_paras - 1:
            changes.append("åˆå¹¶äº†æ®µè½ï¼Œå¢å¼ºæ•´ä½“æ€§")
        
        if not changes:
            changes.append("è°ƒæ•´äº†è¯æ±‡å’Œè¡¨è¾¾æ–¹å¼")
        
        return changes[:MAX_CHANGES_TO_REPORT]  # æœ€å¤šè¿”å›æŒ‡å®šæ•°é‡çš„å˜åŒ–
    
    def get_dedup_report(self, result: DedupResult) -> str:
        """
        ç”Ÿæˆé™é‡æŠ¥å‘Š
        
        Args:
            result: é™é‡ç»“æœ
            
        Returns:
            str: Markdown æ ¼å¼çš„æŠ¥å‘Š
        """
        lines = []
        lines.append("# ğŸ“Š é™é‡å¤„ç†æŠ¥å‘Š\n")
        
        # ç›¸ä¼¼åº¦å˜åŒ–
        reduction = (result.similarity_before - result.similarity_after) * 100
        lines.append(f"## ç›¸ä¼¼åº¦å˜åŒ–")
        lines.append(f"- å¤„ç†å‰ç›¸ä¼¼åº¦ï¼š{result.similarity_before * 100:.1f}%")
        lines.append(f"- å¤„ç†åç›¸ä¼¼åº¦ï¼š{result.similarity_after * 100:.1f}%")
        lines.append(f"- é™é‡å¹…åº¦ï¼š**{reduction:.1f}%**\n")
        
        # ä¿ç•™æœ¯è¯­
        if result.preserved_terms:
            lines.append("## ä¿ç•™çš„ä¸“ä¸šæœ¯è¯­")
            lines.append(", ".join(result.preserved_terms))
            lines.append("")
        
        # ä¸»è¦å˜åŒ–
        lines.append("## ä¸»è¦å˜åŒ–")
        for change in result.changes:
            lines.append(f"- {change}")
        
        return "\n".join(lines)
